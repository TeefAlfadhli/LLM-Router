🧠 LLM Router

An adaptive routing system for Large Language Models (LLMs) that intelligently selects the most cost-effective, fastest, or highest-quality model for a given task. Includes a dashboard for monitoring usage, costs, latency, and A/B testing results for model comparisons.

⸻

🚀 Features
	•	Task classification – Automatically classifies prompts into code, summarization, qa, or general.
	•	Model selection – Routes requests to the best model based on optimization goals (cost, latency, or quality).
	•	A/B testing – Runs all-vs-all model comparisons with automated scoring.
	•	Dashboard – Real-time view of:
	•	Request history
	•	Cost & latency trends
	•	Model usage stats
	•	A/B test summary table
	•	SQLite logging – Persistent request and test results storage.
	•	Flask + Chart.js UI – Clean, dark-themed interface.

⸻

📂 Project Structure

LLM-Router/
│
├── app.py                # Main Flask app
├── ab_test.py            # All-vs-all model A/B testing
├── dashboard.html        # Dashboard UI template
├── index.html            # Main app UI template
├── routing_logs.db       # SQLite database
├── code.json             # Models for 'code' tasks
├── summarization.json    # Models for 'summarization' tasks
├── qa.json               # Models for 'qa' tasks
├── eval_prompts/         # Evaluation prompts for A/B testing
│   └── prompts.json
├── .gitignore
├── requirements.txt
└── README.md


⸻

🛠 Installation
	1.	Clone the repository

git clone https://github.com/TeefAlfadhli/LLM-Router.git
cd LLM-Router


	2.	Create a virtual environment

python3 -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows


	3.	Install dependencies

pip install -r requirements.txt


	4.	Set environment variables
Create a .env file:

ROUTER_KEY=your_openrouter_api_key_here



⸻

▶️ Usage

Start the Flask App

python app.py

Then open:
http://localhost:5000

⸻

📊 Dashboard
	•	Go to: http://localhost:5000/dashboard
	•	View:
	•	Total requests
	•	Average latency
	•	Total estimated cost
	•	Latency & cost over time
	•	Model usage charts
	•	A/B testing results table

⸻

🔬 Running A/B Tests

python ab_test.py

This:
	•	Compares all models in each task category
	•	Uses evaluation prompts from eval_prompts/prompts.json
	•	Logs results to ab_summaries in routing_logs.db
	•	Displays winners in the dashboard

⸻

📌 Example Prompt Classification

Prompt	Task Type
“Summarize this article about AI ethics.”	summarization
“Write a Python function to reverse a string.”	code
“Who is the president of the United States in 2025?”	qa
“Tell me something interesting.”	general


⸻

📦 Requirements
	•	Python 3.8+
	•	Flask
	•	requests
	•	python-dotenv
	•	sqlite3
	•	scipy
	•	chart.js (frontend)

Install all dependencies:

pip install -r requirements.txt


⸻

📝 License

This project is licensed under the MIT License.

⸻

🙌 Acknowledgements
	•	OpenRouter API for model routing
	•	Chart.js for dashboard charts
	•	Flask for backend web server
