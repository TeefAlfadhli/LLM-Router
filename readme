ğŸ§  LLM Router

An adaptive routing system for Large Language Models (LLMs) that intelligently selects the most cost-effective, fastest, or highest-quality model for a given task. Includes a dashboard for monitoring usage, costs, latency, and A/B testing results for model comparisons.

â¸»

ğŸš€ Features
	â€¢	Task classification â€“ Automatically classifies prompts into code, summarization, qa, or general.
	â€¢	Model selection â€“ Routes requests to the best model based on optimization goals (cost, latency, or quality).
	â€¢	A/B testing â€“ Runs all-vs-all model comparisons with automated scoring.
	â€¢	Dashboard â€“ Real-time view of:
	â€¢	Request history
	â€¢	Cost & latency trends
	â€¢	Model usage stats
	â€¢	A/B test summary table
	â€¢	SQLite logging â€“ Persistent request and test results storage.
	â€¢	Flask + Chart.js UI â€“ Clean, dark-themed interface.

â¸»

ğŸ“‚ Project Structure

LLM-Router/
â”‚
â”œâ”€â”€ app.py                # Main Flask app
â”œâ”€â”€ ab_test.py            # All-vs-all model A/B testing
â”œâ”€â”€ dashboard.html        # Dashboard UI template
â”œâ”€â”€ index.html            # Main app UI template
â”œâ”€â”€ routing_logs.db       # SQLite database
â”œâ”€â”€ code.json             # Models for 'code' tasks
â”œâ”€â”€ summarization.json    # Models for 'summarization' tasks
â”œâ”€â”€ qa.json               # Models for 'qa' tasks
â”œâ”€â”€ eval_prompts/         # Evaluation prompts for A/B testing
â”‚   â””â”€â”€ prompts.json
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


â¸»

ğŸ›  Installation
	1.	Clone the repository

git clone https://github.com/TeefAlfadhli/LLM-Router.git
cd LLM-Router


	2.	Create a virtual environment

python3 -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows


	3.	Install dependencies

pip install -r requirements.txt


	4.	Set environment variables
Create a .env file:

ROUTER_KEY=your_openrouter_api_key_here



â¸»

â–¶ï¸ Usage

Start the Flask App

python app.py

Then open:
http://localhost:5000

â¸»

ğŸ“Š Dashboard
	â€¢	Go to: http://localhost:5000/dashboard
	â€¢	View:
	â€¢	Total requests
	â€¢	Average latency
	â€¢	Total estimated cost
	â€¢	Latency & cost over time
	â€¢	Model usage charts
	â€¢	A/B testing results table

â¸»

ğŸ”¬ Running A/B Tests

python ab_test.py

This:
	â€¢	Compares all models in each task category
	â€¢	Uses evaluation prompts from eval_prompts/prompts.json
	â€¢	Logs results to ab_summaries in routing_logs.db
	â€¢	Displays winners in the dashboard

â¸»

ğŸ“Œ Example Prompt Classification

Prompt	Task Type
â€œSummarize this article about AI ethics.â€	summarization
â€œWrite a Python function to reverse a string.â€	code
â€œWho is the president of the United States in 2025?â€	qa
â€œTell me something interesting.â€	general


â¸»

ğŸ“¦ Requirements
	â€¢	Python 3.8+
	â€¢	Flask
	â€¢	requests
	â€¢	python-dotenv
	â€¢	sqlite3
	â€¢	scipy
	â€¢	chart.js (frontend)

Install all dependencies:

pip install -r requirements.txt


â¸»

ğŸ“ License

This project is licensed under the MIT License.

â¸»

ğŸ™Œ Acknowledgements
	â€¢	OpenRouter API for model routing
	â€¢	Chart.js for dashboard charts
	â€¢	Flask for backend web server
